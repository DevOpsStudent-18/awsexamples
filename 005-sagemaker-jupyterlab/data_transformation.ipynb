{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c34e2c-7e4c-48c7-9f0f-47e72834a413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:49.490297Z",
     "iopub.status.busy": "2025-07-21T00:16:49.490002Z",
     "iopub.status.idle": "2025-07-21T00:16:49.494862Z",
     "shell.execute_reply": "2025-07-21T00:16:49.494083Z",
     "shell.execute_reply.started": "2025-07-21T00:16:49.490274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Data Transformation Pipeline\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Data Transformation Pipeline\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91601180-d000-42e2-8982-3cdd41d575f0",
   "metadata": {},
   "source": [
    "# Data Transformation Pipeline for MLOps Using SageMaker Jupyter Notebooks\n",
    "`This notebook demonstrates key data transformation techniques commonly used in machine learning pipelines. It follows MLOps best practices for data preprocessing and feature engineering using AWS SageMaker JupyterLab.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880256bb-d076-4060-adaa-ad2fc830af7d",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "### üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e973b107-b357-4dd0-b794-b04a0f3e3c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:49.496521Z",
     "iopub.status.busy": "2025-07-21T00:16:49.496290Z",
     "iopub.status.idle": "2025-07-21T00:16:52.034187Z",
     "shell.execute_reply": "2025-07-21T00:16:52.033307Z",
     "shell.execute_reply.started": "2025-07-21T00:16:49.496501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "SageMaker Role: arn:aws:iam::910316760829:role/service-role/AmazonSageMaker-ExecutionRole-20250720T171468\n",
      "Default Bucket: sagemaker-us-east-1-910316760829\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Step 1: Setup Environment\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Default Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9baa537-063a-44cd-a4c2-6aa4366a9998",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Step 2: Data Generation\n",
    "Creating a realistic dataset that simulates common data quality challenges found in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4676e5-804d-4d6e-8781-b03b8092be7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:52.035781Z",
     "iopub.status.busy": "2025-07-21T00:16:52.035371Z",
     "iopub.status.idle": "2025-07-21T00:16:52.352593Z",
     "shell.execute_reply": "2025-07-21T00:16:52.351809Z",
     "shell.execute_reply.started": "2025-07-21T00:16:52.035746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created and uploaded to data/mock_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of records\n",
    "num_records = 20000\n",
    "\n",
    "# Generate random data\n",
    "data = {\n",
    "    \"id\": np.arange(1, num_records + 1),\n",
    "    \"name\": [f\"Name_{i}\" for i in np.random.randint(1, 1000, num_records)],\n",
    "    \"age\": np.random.randint(18, 80, num_records),\n",
    "    \"salary\": np.random.choice([50000, 60000, 70000, None], num_records),\n",
    "    \"hire_date\": [\n",
    "        (datetime.now() - timedelta(days=random.randint(0, 3650))).strftime(\"%Y-%m-%d\")\n",
    "        if random.random() > 0.1 else None\n",
    "        for _ in range(num_records)\n",
    "    ],\n",
    "    \"profile\": [\n",
    "        json.dumps({\n",
    "            \"address\": f\"Street {random.randint(1, 100)}, City {random.randint(1, 50)}\",\n",
    "            \"phone\": f\"{random.randint(1000000000, 9999999999)}\",\n",
    "            \"email\": f\"email_{random.randint(1, 1000)}@example.com\"\n",
    "        })\n",
    "        if random.random() > 0.1 else None\n",
    "        for _ in range(num_records)\n",
    "    ],\n",
    "    \"department\": np.random.choice([\"HR\", \"IT\", \"Finance\", \"Marketing\", None], num_records),\n",
    "    \"bonus\": [None if random.random() > 0.9 else random.randint(1000, 10000) for _ in range(num_records)]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some NaN values randomly\n",
    "df.loc[np.random.choice(df.index, size=int(num_records * 0.05), replace=False), \"age\"] = np.nan\n",
    "df.loc[np.random.choice(df.index, size=int(num_records * 0.1), replace=False), \"salary\"] = np.nan\n",
    "\n",
    "# Ensure 'data' folder exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"data/mock_data.csv\", index=False)\n",
    "print(\"Dataset created and uploaded to data/mock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d5e28-a7dc-40f4-8767-6ad631e3e17d",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Step 3: Upload Source Data to S3\n",
    "Upload the source CSV dataset to input location in S3 (default bucket)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbbf0e65-caee-417a-bddc-f8533c6c613c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:52.354049Z",
     "iopub.status.busy": "2025-07-21T00:16:52.353510Z",
     "iopub.status.idle": "2025-07-21T00:16:52.565578Z",
     "shell.execute_reply": "2025-07-21T00:16:52.564367Z",
     "shell.execute_reply.started": "2025-07-21T00:16:52.354019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'mock_data.csv' uploaded to: s3://sagemaker-us-east-1-910316760829/input/mock_data.csv\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file('data/mock_data.csv', bucket, 'input/mock_data.csv')\n",
    "print(f\"Dataset 'mock_data.csv' uploaded to: s3://{bucket}/input/mock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781eaf7-4980-43c7-8608-746ad3666a94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Data Exploration  \n",
    "Load the raw dataset and perform initial data profiling. \n",
    "This step is crucial for understanding data quality and structure. \n",
    "\n",
    "### Step 1: Load the CSV File from S3 into the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23bb077-5661-4295-8e50-9c99e735cd11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:52.567558Z",
     "iopub.status.busy": "2025-07-21T00:16:52.567121Z",
     "iopub.status.idle": "2025-07-21T00:16:53.010938Z",
     "shell.execute_reply": "2025-07-21T00:16:53.010152Z",
     "shell.execute_reply.started": "2025-07-21T00:16:52.567533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "üìè Dataset shape: (20000, 8)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(f's3://{bucket}/input/mock_data.csv')\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìè Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: mock_data.csv not found. Please run create_dataset.py first.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43e7b6-38aa-4919-8b13-17e228bdb968",
   "metadata": {},
   "source": [
    "### Step 2: Analyse the Data  \n",
    "Perform comprehensive data analysis to understand:\n",
    "- Data types and memory usage\n",
    "- Missing values pattern\n",
    "- Statistical distribution\n",
    "- Unique values and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34776ea8-2b8e-4561-b63d-277229f87b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.012739Z",
     "iopub.status.busy": "2025-07-21T00:16:53.012156Z",
     "iopub.status.idle": "2025-07-21T00:16:53.030736Z",
     "shell.execute_reply": "2025-07-21T00:16:53.029944Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.012704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>profile</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Name_103</td>\n",
       "      <td>77.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>6199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Name_436</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>{\"address\": \"Street 45, City 2\", \"phone\": \"162...</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>8305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Name_861</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>{\"address\": \"Street 6, City 34\", \"phone\": \"558...</td>\n",
       "      <td>HR</td>\n",
       "      <td>3904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Name_271</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"address\": \"Street 99, City 20\", \"phone\": \"22...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Name_107</td>\n",
       "      <td>78.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>{\"address\": \"Street 21, City 28\", \"phone\": \"18...</td>\n",
       "      <td>IT</td>\n",
       "      <td>9940.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name   age   salary   hire_date  \\\n",
       "0   1  Name_103  77.0  60000.0  2017-01-03   \n",
       "1   2  Name_436  62.0  50000.0  2017-12-15   \n",
       "2   3  Name_861  61.0  60000.0  2021-02-15   \n",
       "3   4  Name_271  36.0  70000.0         NaN   \n",
       "4   5  Name_107  78.0  60000.0  2017-06-09   \n",
       "\n",
       "                                             profile department   bonus  \n",
       "0                                                NaN  Marketing  6199.0  \n",
       "1  {\"address\": \"Street 45, City 2\", \"phone\": \"162...  Marketing  8305.0  \n",
       "2  {\"address\": \"Street 6, City 34\", \"phone\": \"558...         HR  3904.0  \n",
       "3  {\"address\": \"Street 99, City 20\", \"phone\": \"22...        NaN  6077.0  \n",
       "4  {\"address\": \"Street 21, City 28\", \"phone\": \"18...         IT  9940.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows from the loaded DataFrame\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de2652a-52a8-4ba6-97df-457a332f3cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.031961Z",
     "iopub.status.busy": "2025-07-21T00:16:53.031707Z",
     "iopub.status.idle": "2025-07-21T00:16:53.058765Z",
     "shell.execute_reply": "2025-07-21T00:16:53.058048Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.031932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Types & Non-Null Counts:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          20000 non-null  int64  \n",
      " 1   name        20000 non-null  object \n",
      " 2   age         19000 non-null  float64\n",
      " 3   salary      13519 non-null  float64\n",
      " 4   hire_date   17988 non-null  object \n",
      " 5   profile     17980 non-null  object \n",
      " 6   department  16003 non-null  object \n",
      " 7   bonus       17993 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get the summary of the DataFrame\n",
    "print(\"\\nüìä Data Types & Non-Null Counts:\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab79f216-1000-4333-9310-944de2d8f498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.060001Z",
     "iopub.status.busy": "2025-07-21T00:16:53.059680Z",
     "iopub.status.idle": "2025-07-21T00:16:53.080993Z",
     "shell.execute_reply": "2025-07-21T00:16:53.080315Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.059977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2ee607-aeae-4087-81ab-3e5da46f4346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.082409Z",
     "iopub.status.busy": "2025-07-21T00:16:53.081877Z",
     "iopub.status.idle": "2025-07-21T00:16:53.088625Z",
     "shell.execute_reply": "2025-07-21T00:16:53.087724Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.082384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Marketing', 'HR', nan, 'IT', 'Finance'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values in the department column\n",
    "df['department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26686b8-70c2-4419-87ad-c5bde83cced9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.090662Z",
     "iopub.status.busy": "2025-07-21T00:16:53.090095Z",
     "iopub.status.idle": "2025-07-21T00:16:53.176045Z",
     "shell.execute_reply": "2025-07-21T00:16:53.175151Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.090628Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Statistical Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>profile</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000</td>\n",
       "      <td>19000.000000</td>\n",
       "      <td>13519.000000</td>\n",
       "      <td>17988</td>\n",
       "      <td>17980</td>\n",
       "      <td>16003</td>\n",
       "      <td>17993.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3622</td>\n",
       "      <td>17980</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Name_825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>{\"address\": \"Street 68, City 10\", \"phone\": \"24...</td>\n",
       "      <td>IT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.444684</td>\n",
       "      <td>59962.275316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5480.194909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5773.647028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.892848</td>\n",
       "      <td>8200.588356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2598.626609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5000.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15000.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      name           age        salary   hire_date  \\\n",
       "count   20000.000000     20000  19000.000000  13519.000000       17988   \n",
       "unique           NaN       999           NaN           NaN        3622   \n",
       "top              NaN  Name_825           NaN           NaN  2024-05-22   \n",
       "freq             NaN        37           NaN           NaN          14   \n",
       "mean    10000.500000       NaN     48.444684  59962.275316         NaN   \n",
       "std      5773.647028       NaN     17.892848   8200.588356         NaN   \n",
       "min         1.000000       NaN     18.000000  50000.000000         NaN   \n",
       "25%      5000.750000       NaN     33.000000  50000.000000         NaN   \n",
       "50%     10000.500000       NaN     48.000000  60000.000000         NaN   \n",
       "75%     15000.250000       NaN     64.000000  70000.000000         NaN   \n",
       "max     20000.000000       NaN     79.000000  70000.000000         NaN   \n",
       "\n",
       "                                                  profile department  \\\n",
       "count                                               17980      16003   \n",
       "unique                                              17980          4   \n",
       "top     {\"address\": \"Street 68, City 10\", \"phone\": \"24...         IT   \n",
       "freq                                                    1       4058   \n",
       "mean                                                  NaN        NaN   \n",
       "std                                                   NaN        NaN   \n",
       "min                                                   NaN        NaN   \n",
       "25%                                                   NaN        NaN   \n",
       "50%                                                   NaN        NaN   \n",
       "75%                                                   NaN        NaN   \n",
       "max                                                   NaN        NaN   \n",
       "\n",
       "               bonus  \n",
       "count   17993.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean     5480.194909  \n",
       "std      2598.626609  \n",
       "min      1000.000000  \n",
       "25%      3210.000000  \n",
       "50%      5491.000000  \n",
       "75%      7711.000000  \n",
       "max     10000.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View statistical summary for numeric coloums\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0fa73b-9bea-4d43-acda-d21a38b7e443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.177729Z",
     "iopub.status.busy": "2025-07-21T00:16:53.177267Z",
     "iopub.status.idle": "2025-07-21T00:16:53.189532Z",
     "shell.execute_reply": "2025-07-21T00:16:53.188793Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.177690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Missing Values Analysis:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "name             0\n",
       "age           1000\n",
       "salary        6481\n",
       "hire_date     2012\n",
       "profile       2020\n",
       "department    3997\n",
       "bonus         2007\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n‚ùì Missing Values Analysis:\\n\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ccc74-4242-4579-8b83-d7a537e082b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üßπ 3. Data Cleaning & Quality Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa6405-cbaa-4291-810f-ccb99aedbd6d",
   "metadata": {},
   "source": [
    "### Step 1: Handle Missing values of age, and salary\n",
    "Handle missing values in age and salary columns using appropriate strategies:\n",
    "- For age: Use median (robust to outliers)\n",
    "- For salary: Use median (robust to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b49db1-ac54-410b-9092-534ea82cec0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.191145Z",
     "iopub.status.busy": "2025-07-21T00:16:53.190772Z",
     "iopub.status.idle": "2025-07-21T00:16:53.201268Z",
     "shell.execute_reply": "2025-07-21T00:16:53.200542Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.191039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Missing Value Patterns:\n",
      "Missing Age values:\n",
      "       age   salary department\n",
      "44     NaN  60000.0  Marketing\n",
      "115    NaN  60000.0         IT\n",
      "127    NaN      NaN  Marketing\n",
      "147    NaN  60000.0         HR\n",
      "164    NaN  70000.0         IT\n",
      "...    ...      ...        ...\n",
      "19872  NaN  60000.0         HR\n",
      "19921  NaN      NaN         HR\n",
      "19940  NaN  70000.0        NaN\n",
      "19997  NaN  60000.0         IT\n",
      "19998  NaN  60000.0  Marketing\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing patterns\n",
    "print(\"\\nüìä Missing Value Patterns:\")\n",
    "print(\"Missing Age values:\")\n",
    "print(df[df['age'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b91f6e6-b8a0-4528-8009-dbae08ae21f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.203348Z",
     "iopub.status.busy": "2025-07-21T00:16:53.203006Z",
     "iopub.status.idle": "2025-07-21T00:16:53.213530Z",
     "shell.execute_reply": "2025-07-21T00:16:53.212890Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.203321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Salary values\n",
      "        age  salary department\n",
      "5      35.0     NaN         IT\n",
      "11     61.0     NaN         IT\n",
      "13     46.0     NaN        NaN\n",
      "14     48.0     NaN         IT\n",
      "15     61.0     NaN         HR\n",
      "...     ...     ...        ...\n",
      "19984  71.0     NaN        NaN\n",
      "19988  72.0     NaN  Marketing\n",
      "19992  60.0     NaN        NaN\n",
      "19993  76.0     NaN  Marketing\n",
      "19999  47.0     NaN        NaN\n",
      "\n",
      "[6481 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Salary values\")\n",
    "print(df[df['salary'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12df9538-38f3-42d2-a62e-08e5ba0af6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.227845Z",
     "iopub.status.busy": "2025-07-21T00:16:53.227436Z",
     "iopub.status.idle": "2025-07-21T00:16:53.236217Z",
     "shell.execute_reply": "2025-07-21T00:16:53.235555Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.227818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Median 48.0\n",
      "Salary Median 60000.0\n"
     ]
    }
   ],
   "source": [
    "# Get the median values for age, and salary\n",
    "age_median = df['age'].median()\n",
    "salary_median = df['salary'].median()\n",
    "print(\"Age Median\", age_median)\n",
    "print(\"Salary Median\", salary_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2bc0570-6fc5-464c-81d8-a02a3adba273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.238374Z",
     "iopub.status.busy": "2025-07-21T00:16:53.238045Z",
     "iopub.status.idle": "2025-07-21T00:16:53.244824Z",
     "shell.execute_reply": "2025-07-21T00:16:53.244040Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.238350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill missing values of age with age_median\n",
    "df['age'] = df['age'].fillna(age_median)\n",
    "# Fill missing values of salary with salary_median\n",
    "df['salary'] = df['salary'].fillna(salary_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fb165-2329-462f-a31e-95c68398c2bd",
   "metadata": {},
   "source": [
    "#### Age & Salary columns missing values are filled with the respective median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b85aacbe-1f52-4c17-8e8f-6ad235eb3c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.247085Z",
     "iopub.status.busy": "2025-07-21T00:16:53.246835Z",
     "iopub.status.idle": "2025-07-21T00:16:53.260913Z",
     "shell.execute_reply": "2025-07-21T00:16:53.260296Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.247063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "name             0\n",
       "age              0\n",
       "salary           0\n",
       "hire_date     2012\n",
       "profile       2020\n",
       "department    3997\n",
       "bonus         2007\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the Age & Salary data\n",
    "df.head()\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c09aa2-0bc1-473f-8c76-f19774a5d739",
   "metadata": {},
   "source": [
    "### Step 2: Handle Missing values of Department\n",
    "Handle missing values in categorical columns:\n",
    "- For department: Use 'Unknown' category\n",
    "- This preserves the information that the department was missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47976d92-55aa-47c2-9ff7-6a4e17c63130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.262927Z",
     "iopub.status.busy": "2025-07-21T00:16:53.262626Z",
     "iopub.status.idle": "2025-07-21T00:16:53.274022Z",
     "shell.execute_reply": "2025-07-21T00:16:53.273337Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.262902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the missing values for Department\n",
      "\n",
      "Missing Department Missing values\n",
      "        age   salary department\n",
      "3      36.0  70000.0        NaN\n",
      "13     46.0  60000.0        NaN\n",
      "49     34.0  50000.0        NaN\n",
      "53     33.0  60000.0        NaN\n",
      "57     28.0  70000.0        NaN\n",
      "...     ...      ...        ...\n",
      "19973  50.0  60000.0        NaN\n",
      "19975  29.0  60000.0        NaN\n",
      "19984  71.0  60000.0        NaN\n",
      "19992  60.0  60000.0        NaN\n",
      "19999  47.0  60000.0        NaN\n",
      "\n",
      "[3997 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print the missing values for Department\\n\")\n",
    "print(\"Missing Department Missing values\")\n",
    "print(df[df['department'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e3c4fe-2eff-4254-afc8-72f131d1337a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.275657Z",
     "iopub.status.busy": "2025-07-21T00:16:53.275343Z",
     "iopub.status.idle": "2025-07-21T00:16:53.282046Z",
     "shell.execute_reply": "2025-07-21T00:16:53.281367Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.275627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill the missing values in department with 'Unknown'\n",
    "df['department'] = df['department'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161cef80-1465-4bf7-a5dd-77c98d726590",
   "metadata": {},
   "source": [
    "#### Department column missing values are filled with the respective median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45cc852e-7cad-4d18-bd6a-b5399e65ebb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.284143Z",
     "iopub.status.busy": "2025-07-21T00:16:53.283848Z",
     "iopub.status.idle": "2025-07-21T00:16:53.300134Z",
     "shell.execute_reply": "2025-07-21T00:16:53.299478Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.284119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column\n",
      "id               0\n",
      "name             0\n",
      "age              0\n",
      "salary           0\n",
      "hire_date     2012\n",
      "profile       2020\n",
      "department       0\n",
      "bonus         2007\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Marketing', 'HR', 'Unknown', 'IT', 'Finance'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the Age & Salary data\n",
    "df.head()\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column\")\n",
    "print(df.isnull().sum())\n",
    "# Check unique values in the department column\n",
    "df['department'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df4a53-6359-4802-979d-df7070a57e9a",
   "metadata": {},
   "source": [
    "### Step 3: Parse and Extract Profile Information\n",
    "Devide Profile Column into 3 different columns i.e., Address, Phone, Email   \n",
    "\n",
    "Parse JSON profile data and extract structured information:\n",
    "- Extract address, phone, and email into separate columns\n",
    "- Handle malformed JSON gracefully\n",
    "- Maintain data integrity during extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40e044cc-fb5c-4b9a-a5f2-bfb99b07add1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.302382Z",
     "iopub.status.busy": "2025-07-21T00:16:53.302100Z",
     "iopub.status.idle": "2025-07-21T00:16:53.590587Z",
     "shell.execute_reply": "2025-07-21T00:16:53.589812Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.302357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top rows from profile column \n",
      "\n",
      "0                                                  NaN\n",
      "1    {\"address\": \"Street 45, City 2\", \"phone\": \"162...\n",
      "2    {\"address\": \"Street 6, City 34\", \"phone\": \"558...\n",
      "3    {\"address\": \"Street 99, City 20\", \"phone\": \"22...\n",
      "4    {\"address\": \"Street 21, City 28\", \"phone\": \"18...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Profile column values current data type\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "\n",
    "# Find the first non-null value in the column\n",
    "profile_first_value = df['profile'].dropna().iloc[0]\n",
    "# Print its type\n",
    "print(\"\\nProfile column values current data type\")\n",
    "print(type(profile_first_value))\n",
    "\n",
    "# If your 'profile' column already contains Python dictionaries, not JSON strings.\n",
    "# You do not need to parse it with json.loads(). The data is ready to be used directly.\n",
    "\n",
    "# Convert profile JSON strings into dictionaries\n",
    "df['profile'] = df['profile'].apply(lambda x: json.loads(x) if pd.notnull(x) else {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10b5d994-5d55-438e-93fd-ff2042cffffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.592897Z",
     "iopub.status.busy": "2025-07-21T00:16:53.592513Z",
     "iopub.status.idle": "2025-07-21T00:16:53.609066Z",
     "shell.execute_reply": "2025-07-21T00:16:53.608314Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.592872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Address Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0                                                   {}\n",
      "1    {'address': 'Street 45, City 2', 'phone': '162...\n",
      "2    {'address': 'Street 6, City 34', 'phone': '558...\n",
      "3    {'address': 'Street 99, City 20', 'phone': '22...\n",
      "4    {'address': 'Street 21, City 28', 'phone': '18...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created address column \n",
      "\n",
      "0                  None\n",
      "1     Street 45, City 2\n",
      "2     Street 6, City 34\n",
      "3    Street 99, City 20\n",
      "4    Street 21, City 28\n",
      "Name: address, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract Address Field\n",
    "print(\"Extract Address Field....\\n\")\n",
    "# Create new 'address' column by extracting from 'profile' dictionaries\n",
    "df['address'] = df['profile'].apply(lambda x: x.get('address', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created address column \\n\")\n",
    "print(df['address'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af5fbe45-27ac-4eef-992f-79d4895060a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.610408Z",
     "iopub.status.busy": "2025-07-21T00:16:53.610097Z",
     "iopub.status.idle": "2025-07-21T00:16:53.623481Z",
     "shell.execute_reply": "2025-07-21T00:16:53.622804Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.610378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Phone Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0                                                   {}\n",
      "1    {'address': 'Street 45, City 2', 'phone': '162...\n",
      "2    {'address': 'Street 6, City 34', 'phone': '558...\n",
      "3    {'address': 'Street 99, City 20', 'phone': '22...\n",
      "4    {'address': 'Street 21, City 28', 'phone': '18...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created phone column \n",
      "\n",
      "0          None\n",
      "1    1621025422\n",
      "2    5589424988\n",
      "3    2299788720\n",
      "4    1833307230\n",
      "Name: phone, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract Phone Field\n",
    "print(\"Extract Phone Field....\\n\")\n",
    "# Create new 'phone' column by extracting from 'profile' dictionaries\n",
    "df['phone'] = df['profile'].apply(lambda x: x.get('phone', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created phone column \\n\")\n",
    "print(df['phone'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aebdb099-5095-4149-b957-119ae9fccaa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.624931Z",
     "iopub.status.busy": "2025-07-21T00:16:53.624601Z",
     "iopub.status.idle": "2025-07-21T00:16:53.638441Z",
     "shell.execute_reply": "2025-07-21T00:16:53.637766Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.624901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Email Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0                                                   {}\n",
      "1    {'address': 'Street 45, City 2', 'phone': '162...\n",
      "2    {'address': 'Street 6, City 34', 'phone': '558...\n",
      "3    {'address': 'Street 99, City 20', 'phone': '22...\n",
      "4    {'address': 'Street 21, City 28', 'phone': '18...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created email column \n",
      "\n",
      "0                     None\n",
      "1    email_599@example.com\n",
      "2      email_7@example.com\n",
      "3    email_349@example.com\n",
      "4    email_951@example.com\n",
      "Name: email, dtype: object\n",
      "\n",
      "‚úÖ Profile fields extracted:\n"
     ]
    }
   ],
   "source": [
    "# Extract Email Field\n",
    "print(\"Extract Email Field....\\n\")\n",
    "# Create new 'email' column by extracting from 'profile' dictionaries\n",
    "df['email'] = df['profile'].apply(lambda x: x.get('email', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created email column \\n\")\n",
    "print(df['email'].head())\n",
    "\n",
    "print(f\"\\n‚úÖ Profile fields extracted:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ee1aeb4-dac9-40f4-8455-1a24e1e8ff1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.640451Z",
     "iopub.status.busy": "2025-07-21T00:16:53.640185Z",
     "iopub.status.idle": "2025-07-21T00:16:53.650492Z",
     "shell.execute_reply": "2025-07-21T00:16:53.649876Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.640428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns before dropping profile:\n",
      "['id', 'name', 'age', 'salary', 'hire_date', 'profile', 'department', 'bonus', 'address', 'phone', 'email']\n",
      "\n",
      "Columns in new DataFrame after dropping profile:\n",
      "['id', 'name', 'age', 'salary', 'hire_date', 'department', 'bonus', 'address', 'phone', 'email']\n"
     ]
    }
   ],
   "source": [
    "# Now drop the profile column\n",
    "print(\"\\nColumns before dropping profile:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Without inplace=True (df remains unchanged)\n",
    "cleaned_df = df.drop(columns=['profile'])\n",
    "\n",
    "# With inplace=True (df is modified directly)\n",
    "#df.drop(columns=['profile'], inplace=True)\n",
    "\n",
    "print(\"\\nColumns in new DataFrame after dropping profile:\")\n",
    "# print(df.columns.tolist())\n",
    "print(cleaned_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb385e-e37f-41ec-9c6b-5634419dc89a",
   "metadata": {},
   "source": [
    "### Step 4: Save cleaned data into new CSV and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f9bfbc-83de-433d-8461-d43f5d088731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.652802Z",
     "iopub.status.busy": "2025-07-21T00:16:53.652510Z",
     "iopub.status.idle": "2025-07-21T00:16:53.868843Z",
     "shell.execute_reply": "2025-07-21T00:16:53.868043Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.652780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saving cleaned data to: 'data/cleaned_data.csv' ...\n",
      "‚úÖ Cleaned data saved to: 'data/cleaned_data.csv'\n",
      "\n",
      "Uploading dataset to s3 bucket: sagemaker-us-east-1-910316760829\n",
      "Dataset 'mock_data.csv' uploaded to: s3://sagemaker-us-east-1-910316760829/output/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíæ Saving cleaned data to: 'data/cleaned_data.csv' ...\")\n",
    "cleaned_df.to_csv(\"data/cleaned_data.csv\", index=False)\n",
    "print(\"‚úÖ Cleaned data saved to: 'data/cleaned_data.csv'\")\n",
    "\n",
    "print(f\"\\nUploading dataset to s3 bucket: {bucket}\")\n",
    "s3.meta.client.upload_file('data/cleaned_data.csv', bucket, 'output/cleaned_data.csv')\n",
    "print(f\"Dataset 'mock_data.csv' uploaded to: s3://{bucket}/output/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb68ace-9dce-4caf-9217-a25106886373",
   "metadata": {},
   "source": [
    "## 4. Data Transformation & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41937110-6255-4cc3-a4ce-cfb0d7fb91d2",
   "metadata": {},
   "source": [
    "### Step 1: Load the cleaned dataset into new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f36252c-0d27-44c4-9a51-25876ee35fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.869705Z",
     "iopub.status.busy": "2025-07-21T00:16:53.869496Z",
     "iopub.status.idle": "2025-07-21T00:16:53.961075Z",
     "shell.execute_reply": "2025-07-21T00:16:53.960236Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.869686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Name_103</td>\n",
       "      <td>77.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>6199.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Name_436</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>8305.0</td>\n",
       "      <td>Street 45, City 2</td>\n",
       "      <td>1.621025e+09</td>\n",
       "      <td>email_599@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Name_861</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>HR</td>\n",
       "      <td>3904.0</td>\n",
       "      <td>Street 6, City 34</td>\n",
       "      <td>5.589425e+09</td>\n",
       "      <td>email_7@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Name_271</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>6077.0</td>\n",
       "      <td>Street 99, City 20</td>\n",
       "      <td>2.299789e+09</td>\n",
       "      <td>email_349@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Name_107</td>\n",
       "      <td>78.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>IT</td>\n",
       "      <td>9940.0</td>\n",
       "      <td>Street 21, City 28</td>\n",
       "      <td>1.833307e+09</td>\n",
       "      <td>email_951@example.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name   age   salary   hire_date department   bonus  \\\n",
       "0   1  Name_103  77.0  60000.0  2017-01-03  Marketing  6199.0   \n",
       "1   2  Name_436  62.0  50000.0  2017-12-15  Marketing  8305.0   \n",
       "2   3  Name_861  61.0  60000.0  2021-02-15         HR  3904.0   \n",
       "3   4  Name_271  36.0  70000.0         NaN    Unknown  6077.0   \n",
       "4   5  Name_107  78.0  60000.0  2017-06-09         IT  9940.0   \n",
       "\n",
       "              address         phone                  email  \n",
       "0                 NaN           NaN                    NaN  \n",
       "1   Street 45, City 2  1.621025e+09  email_599@example.com  \n",
       "2   Street 6, City 34  5.589425e+09    email_7@example.com  \n",
       "3  Street 99, City 20  2.299789e+09  email_349@example.com  \n",
       "4  Street 21, City 28  1.833307e+09  email_951@example.com  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df = pd.read_csv(f's3://{bucket}/output/cleaned_data.csv')\n",
    "transform_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4589364-d7f7-4d82-a6a3-873ded9a45e0",
   "metadata": {},
   "source": [
    "### Step 2 : Feature Engineering - Address Length\n",
    "Create address length feature for potential geographic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5054fd88-4a6f-4a78-a1e1-777b05db61e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.962210Z",
     "iopub.status.busy": "2025-07-21T00:16:53.961985Z",
     "iopub.status.idle": "2025-07-21T00:16:53.986667Z",
     "shell.execute_reply": "2025-07-21T00:16:53.985999Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.962191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Address Length Feature...\n",
      "Address followed by Address Length columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Street 45, City 2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Street 6, City 34</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street 99, City 20</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Street 21, City 28</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              address  address_length\n",
       "0                 NaN               3\n",
       "1   Street 45, City 2              17\n",
       "2   Street 6, City 34              17\n",
       "3  Street 99, City 20              18\n",
       "4  Street 21, City 28              18"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'address_length' \n",
    "print(\"\\nüîß Creating Address Length Feature...\")\n",
    "transform_df['address_length'] = transform_df['address'].apply(lambda x: len(str(x)))\n",
    "print(\"Address followed by Address Length columns\")\n",
    "transform_df[['address', 'address_length']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a3a74-21ab-42bb-a0c0-3654bd30762e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 3: Feature Engineering - Salary Categorization\n",
    "Create salary categories for easier analysis and modeling.  \n",
    "This converts continuous salary into ordinal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8273466c-9379-4d78-b658-0837258d5cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:53.988199Z",
     "iopub.status.busy": "2025-07-21T00:16:53.987714Z",
     "iopub.status.idle": "2025-07-21T00:16:54.002967Z",
     "shell.execute_reply": "2025-07-21T00:16:54.002025Z",
     "shell.execute_reply.started": "2025-07-21T00:16:53.988166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Salary Categories...\n",
      "Sample data after adding the 'salary_category' column: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salary salary_category\n",
       "0  60000.0          medium\n",
       "1  50000.0             low\n",
       "2  60000.0          medium\n",
       "3  70000.0          medium\n",
       "4  60000.0          medium"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nüîß Creating Salary Categories...\")\n",
    "# Define the bins and labels\n",
    "bins = [0, 50000, 70000, 100000]\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# Create a new column 'salary_category'\n",
    "transform_df['salary_category'] = pd.cut(df['salary'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Print sample data after adding the 'salary_category' column\n",
    "print(\"Sample data after adding the 'salary_category' column: \\n\")\n",
    "transform_df[['salary', 'salary_category']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5499d-ae91-4868-a45a-873757984b1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 4: Feature Engineering - Age Groups  \n",
    "Create age groups for demographic analysis.  \n",
    "This helps in understanding age-based patterns in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a60a508-591e-4bc8-a8dc-21b8ef5f15d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:54.004483Z",
     "iopub.status.busy": "2025-07-21T00:16:54.004068Z",
     "iopub.status.idle": "2025-07-21T00:16:54.018950Z",
     "shell.execute_reply": "2025-07-21T00:16:54.018081Z",
     "shell.execute_reply.started": "2025-07-21T00:16:54.004449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Age Groups...\n",
      "Age group distribution:\n",
      "age_group\n",
      "Experienced     7318\n",
      "Senior          4068\n",
      "Early Career    3142\n",
      "Mid Career      3022\n",
      "Young           2450\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data after adding the 'age_group' column: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Mid Career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    age_group\n",
       "0  77.0  Experienced\n",
       "1  62.0  Experienced\n",
       "2  61.0  Experienced\n",
       "3  36.0   Mid Career\n",
       "4  78.0  Experienced"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nüîß Creating Age Groups...\")\n",
    "# Define age bins and labels\n",
    "age_bins = [0, 25, 35, 45, 55, float('inf')]\n",
    "age_labels = ['Young', 'Early Career', 'Mid Career', 'Senior', 'Experienced']\n",
    "\n",
    "# Create a new column 'salary_category'\n",
    "transform_df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "# Age group distribution\n",
    "print(f\"Age group distribution:\")\n",
    "print(transform_df['age_group'].value_counts())\n",
    "\n",
    "# Print sample data after adding the 'salary_category' column\n",
    "print(\"\\nSample data after adding the 'age_group' column: \\n\")\n",
    "transform_df[['age', 'age_group']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4adf8-b0e4-4bb6-983b-1ee7754fa7c7",
   "metadata": {},
   "source": [
    "### Step 5: Aggregation Features - Department Statistics  \n",
    "Create department-level aggregations for comparative analysis.  \n",
    "This enables understanding of department-wise patterns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1783afe-aa59-41c5-b48f-e44040e821ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:54.020712Z",
     "iopub.status.busy": "2025-07-21T00:16:54.020140Z",
     "iopub.status.idle": "2025-07-21T00:16:54.031518Z",
     "shell.execute_reply": "2025-07-21T00:16:54.030621Z",
     "shell.execute_reply.started": "2025-07-21T00:16:54.020664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Department Statistics...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Creating Department Statistics...\")\n",
    "# Group by 'department' and calculate average salary and age\n",
    "department_summary_report = df.groupby('department').agg({\n",
    "    'salary': 'mean',\n",
    "    'age': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# rename columns of department_summary_report for clarity\n",
    "department_summary_report.columns = ['Department', 'Average Salary', 'Average Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "375b84ae-6bac-4654-b6ee-616982e3c26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:54.033452Z",
     "iopub.status.busy": "2025-07-21T00:16:54.032830Z",
     "iopub.status.idle": "2025-07-21T00:16:54.039827Z",
     "shell.execute_reply": "2025-07-21T00:16:54.038857Z",
     "shell.execute_reply.started": "2025-07-21T00:16:54.033415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary report of average salary and age based on the department:\n",
      "\n",
      "  Department  Average Salary  Average Age\n",
      "0    Finance    59830.035515    48.345256\n",
      "1         HR    60015.155342    48.620106\n",
      "2         IT    60034.499754    48.650074\n",
      "3  Marketing    60049.455984    48.419139\n",
      "4    Unknown    59939.954966    48.075056\n"
     ]
    }
   ],
   "source": [
    "# Print the Summary Report\n",
    "print(\"Summary report of average salary and age based on the department:\\n\")\n",
    "print(department_summary_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51943479-aee6-4538-9ad4-1e6571d6a661",
   "metadata": {},
   "source": [
    "### Step 6: Data Quality Metrics\n",
    "Calculate data quality metrics for monitoring and MLOps.  \n",
    "These metrics help track data drift and quality over time.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c1a7779-1960-44d6-869a-3e52055a6fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:54.041546Z",
     "iopub.status.busy": "2025-07-21T00:16:54.040963Z",
     "iopub.status.idle": "2025-07-21T00:16:54.076237Z",
     "shell.execute_reply": "2025-07-21T00:16:54.075471Z",
     "shell.execute_reply.started": "2025-07-21T00:16:54.041513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Quality Metrics...\n",
      "Data Quality Metrics:\n",
      "  total_rows: 20000\n",
      "  total_columns: 13\n",
      "  missing_values_count: 10079\n",
      "  duplicate_rows: 0\n",
      "  numeric_columns: 6\n",
      "  categorical_columns: 5\n",
      "  unique_departments: 5\n",
      "  unique_age_groups: 5\n",
      "  unique_salary_categories: 2\n",
      "  processing_timestamp: 2025-07-21T00:16:54.071555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüìä Data Quality Metrics...\")\n",
    "\n",
    "quality_metrics = {\n",
    "    'total_rows': len(transform_df),\n",
    "    'total_columns': len(transform_df.columns),\n",
    "    'missing_values_count': transform_df.isnull().sum().sum(),\n",
    "    'duplicate_rows': transform_df.duplicated().sum(),\n",
    "    'numeric_columns': len(transform_df.select_dtypes(include=[np.number]).columns),\n",
    "    'categorical_columns': len(transform_df.select_dtypes(include=['object']).columns),\n",
    "    'unique_departments': transform_df['department'].nunique(),\n",
    "    'unique_age_groups': transform_df['age_group'].nunique(),\n",
    "    'unique_salary_categories': transform_df['salary_category'].nunique(),\n",
    "    'processing_timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "print(\"Data Quality Metrics:\")\n",
    "for metric, value in quality_metrics.items():\n",
    "    print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc636561-1dd7-464e-b908-de230785c662",
   "metadata": {},
   "source": [
    "### Step 7: Save the transformed DataFrame to a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "effa94fc-c979-4bda-a3bd-fb00e38457ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:54.077418Z",
     "iopub.status.busy": "2025-07-21T00:16:54.077107Z",
     "iopub.status.idle": "2025-07-21T00:16:54.329981Z",
     "shell.execute_reply": "2025-07-21T00:16:54.329255Z",
     "shell.execute_reply.started": "2025-07-21T00:16:54.077388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Transformed data csv to: 'data/transformed_data.csv' ...\n",
      "\n",
      "Transformed data csv saved to: 'data/transformed_data.csv'\n",
      "Transformed data 'transformed_data.csv' uploaded to: s3://sagemaker-us-east-1-910316760829/output/transformed_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving Transformed data csv to: 'data/transformed_data.csv' ...\")\n",
    "transform_df.to_csv(\"data/transformed_data.csv\", index=False)\n",
    "print(\"\\nTransformed data csv saved to: 'data/transformed_data.csv'\")\n",
    "\n",
    "s3.meta.client.upload_file('data/transformed_data.csv', bucket, 'output/transformed_data.csv')\n",
    "print(f\"Transformed data 'transformed_data.csv' uploaded to: s3://{bucket}/output/transformed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ec6fec1-9c65-446c-ac25-d24436689a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:54.330985Z",
     "iopub.status.busy": "2025-07-21T00:16:54.330774Z",
     "iopub.status.idle": "2025-07-21T00:16:54.364774Z",
     "shell.execute_reply": "2025-07-21T00:16:54.363911Z",
     "shell.execute_reply.started": "2025-07-21T00:16:54.330966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving department statistics...\n",
      "‚úÖ Department statistics saved to: 'data/department_statistics.csv'\n",
      "Department Statistics 'department_statistics.csv' uploaded to: s3://sagemaker-us-east-1-910316760829/output/department_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "### Step 2: Save Department Statistics\n",
    "print(\"Saving department statistics...\")\n",
    "department_summary_report.to_csv(\"data/department_statistics.csv\", index=False)\n",
    "print(\"‚úÖ Department statistics saved to: 'data/department_statistics.csv'\")\n",
    "\n",
    "s3.meta.client.upload_file('data/department_statistics.csv', bucket, 'output/department_statistics.csv')\n",
    "print(f\"Department Statistics 'department_statistics.csv' uploaded to: s3://{bucket}/output/department_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2d6f8-27a3-43ad-9e83-fdbf92a2fe23",
   "metadata": {},
   "source": [
    "## 5. Next Steps for MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3ab1b76-7e48-4105-8720-f35ed5584607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T00:16:54.366200Z",
     "iopub.status.busy": "2025-07-21T00:16:54.365565Z",
     "iopub.status.idle": "2025-07-21T00:16:54.372309Z",
     "shell.execute_reply": "2025-07-21T00:16:54.371602Z",
     "shell.execute_reply.started": "2025-07-21T00:16:54.366176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Next Steps for MLOps:\n",
      "  1. Model training using transformed features\n",
      "  2. Model validation and testing\n",
      "  3. Model deployment and monitoring\n",
      "  4. Data drift monitoring using quality metrics\n",
      "  5. Pipeline automation and orchestration\n",
      "\n",
      "==================================================\n",
      "üéâ DATA TRANSFORMATION PIPELINE COMPLETE!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüéØ Next Steps for MLOps:\")\n",
    "print(f\"  1. Model training using transformed features\")\n",
    "print(f\"  2. Model validation and testing\")\n",
    "print(f\"  3. Model deployment and monitoring\")\n",
    "print(f\"  4. Data drift monitoring using quality metrics\")\n",
    "print(f\"  5. Pipeline automation and orchestration\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ DATA TRANSFORMATION PIPELINE COMPLETE!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
