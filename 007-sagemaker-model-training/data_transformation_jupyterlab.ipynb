{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "64c34e2c-7e4c-48c7-9f0f-47e72834a413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:50.651578Z",
     "iopub.status.busy": "2025-07-27T19:17:50.650936Z",
     "iopub.status.idle": "2025-07-27T19:17:50.654975Z",
     "shell.execute_reply": "2025-07-27T19:17:50.654394Z",
     "shell.execute_reply.started": "2025-07-27T19:17:50.651554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Data Transformation Pipeline\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Data Transformation Pipeline\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91601180-d000-42e2-8982-3cdd41d575f0",
   "metadata": {},
   "source": [
    "# Data Transformation Pipeline for MLOps Using SageMaker Jupyter Notebooks\n",
    "`This notebook demonstrates key data transformation techniques commonly used in machine learning pipelines. It follows MLOps best practices for data preprocessing and feature engineering using AWS SageMaker JupyterLab.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880256bb-d076-4060-adaa-ad2fc830af7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "### üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e973b107-b357-4dd0-b794-b04a0f3e3c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:50.660757Z",
     "iopub.status.busy": "2025-07-27T19:17:50.660073Z",
     "iopub.status.idle": "2025-07-27T19:17:50.987858Z",
     "shell.execute_reply": "2025-07-27T19:17:50.987166Z",
     "shell.execute_reply.started": "2025-07-27T19:17:50.660735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role: arn:aws:iam::891377300841:role/cfst-4286-a3bb98dd86788b99c4-SageMakerExecutionRole-cN71NiG3F0e1\n",
      "Default Bucket: sagemaker-us-east-1-891377300841\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Step 1: Setup Environment\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Default Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9baa537-063a-44cd-a4c2-6aa4366a9998",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ‚öôÔ∏è Step 2: Data Generation\n",
    "Creating a realistic dataset that simulates common data quality challenges found in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb4676e5-804d-4d6e-8781-b03b8092be7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:50.990493Z",
     "iopub.status.busy": "2025-07-27T19:17:50.988850Z",
     "iopub.status.idle": "2025-07-27T19:17:51.316382Z",
     "shell.execute_reply": "2025-07-27T19:17:51.315437Z",
     "shell.execute_reply.started": "2025-07-27T19:17:50.990465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created and uploaded to data/mock_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of records\n",
    "num_records = 20000\n",
    "\n",
    "# Generate random data\n",
    "data = {\n",
    "    \"id\": np.arange(1, num_records + 1),\n",
    "    \"name\": [f\"Name_{i}\" for i in np.random.randint(1, 1000, num_records)],\n",
    "    \"age\": np.random.randint(18, 80, num_records),\n",
    "    \"salary\": np.random.choice([50000, 60000, 70000, None], num_records),\n",
    "    \"hire_date\": [\n",
    "        (datetime.now() - timedelta(days=random.randint(0, 3650))).strftime(\"%Y-%m-%d\")\n",
    "        if random.random() > 0.1 else None\n",
    "        for _ in range(num_records)\n",
    "    ],\n",
    "    \"profile\": [\n",
    "        json.dumps({\n",
    "            \"address\": f\"Street {random.randint(1, 100)}, City {random.randint(1, 50)}\",\n",
    "            \"phone\": f\"{random.randint(1000000000, 9999999999)}\",\n",
    "            \"email\": f\"email_{random.randint(1, 1000)}@example.com\"\n",
    "        })\n",
    "        if random.random() > 0.1 else None\n",
    "        for _ in range(num_records)\n",
    "    ],\n",
    "    \"department\": np.random.choice([\"HR\", \"IT\", \"Finance\", \"Marketing\", None], num_records),\n",
    "    \"bonus\": [None if random.random() > 0.9 else random.randint(1000, 10000) for _ in range(num_records)]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some NaN values randomly\n",
    "df.loc[np.random.choice(df.index, size=int(num_records * 0.05), replace=False), \"age\"] = np.nan\n",
    "df.loc[np.random.choice(df.index, size=int(num_records * 0.1), replace=False), \"salary\"] = np.nan\n",
    "\n",
    "# Ensure 'data' folder exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"data/mock_data.csv\", index=False)\n",
    "print(\"Dataset created and uploaded to data/mock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d5e28-a7dc-40f4-8767-6ad631e3e17d",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Step 3: Upload Source Data to S3\n",
    "Upload the source CSV dataset to input location in S3 (default bucket)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cbbf0e65-caee-417a-bddc-f8533c6c613c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.317895Z",
     "iopub.status.busy": "2025-07-27T19:17:51.317602Z",
     "iopub.status.idle": "2025-07-27T19:17:51.485673Z",
     "shell.execute_reply": "2025-07-27T19:17:51.484844Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.317868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'mock_data.csv' uploaded to: s3://sagemaker-us-east-1-891377300841/input/mock_data.csv\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file('data/mock_data.csv', bucket, 'input/mock_data.csv')\n",
    "print(f\"Dataset 'mock_data.csv' uploaded to: s3://{bucket}/input/mock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781eaf7-4980-43c7-8608-746ad3666a94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Data Exploration  \n",
    "Load the raw dataset and perform initial data profiling. \n",
    "This step is crucial for understanding data quality and structure. \n",
    "\n",
    "### Step 1: Load the CSV File from S3 into the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d23bb077-5661-4295-8e50-9c99e735cd11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.487828Z",
     "iopub.status.busy": "2025-07-27T19:17:51.487470Z",
     "iopub.status.idle": "2025-07-27T19:17:51.698442Z",
     "shell.execute_reply": "2025-07-27T19:17:51.697586Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.487807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "üìè Dataset shape: (20000, 8)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(f's3://{bucket}/input/mock_data.csv')\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìè Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: mock_data.csv not found. Please run create_dataset.py first.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43e7b6-38aa-4919-8b13-17e228bdb968",
   "metadata": {},
   "source": [
    "### Step 2: Analyse the Data  \n",
    "Perform comprehensive data analysis to understand:\n",
    "- Data types and memory usage\n",
    "- Missing values pattern\n",
    "- Statistical distribution\n",
    "- Unique values and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "34776ea8-2b8e-4561-b63d-277229f87b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.699968Z",
     "iopub.status.busy": "2025-07-27T19:17:51.699364Z",
     "iopub.status.idle": "2025-07-27T19:17:51.712011Z",
     "shell.execute_reply": "2025-07-27T19:17:51.710991Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.699936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>profile</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Name_103</td>\n",
       "      <td>77.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>{\"address\": \"Street 51, City 12\", \"phone\": \"73...</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>8767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Name_436</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>{\"address\": \"Street 12, City 6\", \"phone\": \"963...</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>7553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Name_861</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HR</td>\n",
       "      <td>6796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Name_271</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"address\": \"Street 17, City 5\", \"phone\": \"842...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Name_107</td>\n",
       "      <td>78.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2017-06-17</td>\n",
       "      <td>{\"address\": \"Street 98, City 37\", \"phone\": \"81...</td>\n",
       "      <td>IT</td>\n",
       "      <td>3340.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name   age   salary   hire_date  \\\n",
       "0   1  Name_103  77.0  60000.0  2023-05-11   \n",
       "1   2  Name_436  62.0  50000.0  2021-04-22   \n",
       "2   3  Name_861  61.0  60000.0  2022-04-18   \n",
       "3   4  Name_271  36.0  70000.0         NaN   \n",
       "4   5  Name_107  78.0  60000.0  2017-06-17   \n",
       "\n",
       "                                             profile department   bonus  \n",
       "0  {\"address\": \"Street 51, City 12\", \"phone\": \"73...  Marketing  8767.0  \n",
       "1  {\"address\": \"Street 12, City 6\", \"phone\": \"963...  Marketing  7553.0  \n",
       "2                                                NaN         HR  6796.0  \n",
       "3  {\"address\": \"Street 17, City 5\", \"phone\": \"842...        NaN  8712.0  \n",
       "4  {\"address\": \"Street 98, City 37\", \"phone\": \"81...         IT  3340.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows from the loaded DataFrame\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0de2652a-52a8-4ba6-97df-457a332f3cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.713065Z",
     "iopub.status.busy": "2025-07-27T19:17:51.712840Z",
     "iopub.status.idle": "2025-07-27T19:17:51.726999Z",
     "shell.execute_reply": "2025-07-27T19:17:51.726236Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.713046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Types & Non-Null Counts:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          20000 non-null  int64  \n",
      " 1   name        20000 non-null  object \n",
      " 2   age         19000 non-null  float64\n",
      " 3   salary      13519 non-null  float64\n",
      " 4   hire_date   17934 non-null  object \n",
      " 5   profile     17967 non-null  object \n",
      " 6   department  16003 non-null  object \n",
      " 7   bonus       18001 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get the summary of the DataFrame\n",
    "print(\"\\nüìä Data Types & Non-Null Counts:\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ab79f216-1000-4333-9310-944de2d8f498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.728352Z",
     "iopub.status.busy": "2025-07-27T19:17:51.728046Z",
     "iopub.status.idle": "2025-07-27T19:17:51.745063Z",
     "shell.execute_reply": "2025-07-27T19:17:51.744298Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.728325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5d2ee607-aeae-4087-81ab-3e5da46f4346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.746626Z",
     "iopub.status.busy": "2025-07-27T19:17:51.746308Z",
     "iopub.status.idle": "2025-07-27T19:17:51.752028Z",
     "shell.execute_reply": "2025-07-27T19:17:51.751263Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.746598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Marketing', 'HR', nan, 'IT', 'Finance'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values in the department column\n",
    "df['department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d26686b8-70c2-4419-87ad-c5bde83cced9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.753909Z",
     "iopub.status.busy": "2025-07-27T19:17:51.753216Z",
     "iopub.status.idle": "2025-07-27T19:17:51.807305Z",
     "shell.execute_reply": "2025-07-27T19:17:51.806650Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.753876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Statistical Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>profile</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000</td>\n",
       "      <td>19000.000000</td>\n",
       "      <td>13519.000000</td>\n",
       "      <td>17934</td>\n",
       "      <td>17967</td>\n",
       "      <td>16003</td>\n",
       "      <td>18001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3634</td>\n",
       "      <td>17967</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Name_825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>{\"address\": \"Street 55, City 12\", \"phone\": \"76...</td>\n",
       "      <td>IT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.444684</td>\n",
       "      <td>59962.275316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5517.326149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5773.647028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.892848</td>\n",
       "      <td>8200.588356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2608.397456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5000.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3247.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5531.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15000.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      name           age        salary   hire_date  \\\n",
       "count   20000.000000     20000  19000.000000  13519.000000       17934   \n",
       "unique           NaN       999           NaN           NaN        3634   \n",
       "top              NaN  Name_825           NaN           NaN  2020-09-14   \n",
       "freq             NaN        37           NaN           NaN          14   \n",
       "mean    10000.500000       NaN     48.444684  59962.275316         NaN   \n",
       "std      5773.647028       NaN     17.892848   8200.588356         NaN   \n",
       "min         1.000000       NaN     18.000000  50000.000000         NaN   \n",
       "25%      5000.750000       NaN     33.000000  50000.000000         NaN   \n",
       "50%     10000.500000       NaN     48.000000  60000.000000         NaN   \n",
       "75%     15000.250000       NaN     64.000000  70000.000000         NaN   \n",
       "max     20000.000000       NaN     79.000000  70000.000000         NaN   \n",
       "\n",
       "                                                  profile department  \\\n",
       "count                                               17967      16003   \n",
       "unique                                              17967          4   \n",
       "top     {\"address\": \"Street 55, City 12\", \"phone\": \"76...         IT   \n",
       "freq                                                    1       4058   \n",
       "mean                                                  NaN        NaN   \n",
       "std                                                   NaN        NaN   \n",
       "min                                                   NaN        NaN   \n",
       "25%                                                   NaN        NaN   \n",
       "50%                                                   NaN        NaN   \n",
       "75%                                                   NaN        NaN   \n",
       "max                                                   NaN        NaN   \n",
       "\n",
       "               bonus  \n",
       "count   18001.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean     5517.326149  \n",
       "std      2608.397456  \n",
       "min      1000.000000  \n",
       "25%      3247.000000  \n",
       "50%      5531.000000  \n",
       "75%      7783.000000  \n",
       "max     10000.000000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View statistical summary for numeric coloums\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ff0fa73b-9bea-4d43-acda-d21a38b7e443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.809966Z",
     "iopub.status.busy": "2025-07-27T19:17:51.809727Z",
     "iopub.status.idle": "2025-07-27T19:17:51.821811Z",
     "shell.execute_reply": "2025-07-27T19:17:51.821010Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.809947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Missing Values Analysis:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "name             0\n",
       "age           1000\n",
       "salary        6481\n",
       "hire_date     2066\n",
       "profile       2033\n",
       "department    3997\n",
       "bonus         1999\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n‚ùì Missing Values Analysis:\\n\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ccc74-4242-4579-8b83-d7a537e082b5",
   "metadata": {},
   "source": [
    "## üßπ 3. Data Cleaning & Quality Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa6405-cbaa-4291-810f-ccb99aedbd6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 1: Handle Missing values of age, and salary\n",
    "Handle missing values in age and salary columns using appropriate strategies:\n",
    "- For age: Use median (robust to outliers)\n",
    "- For salary: Use median (robust to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53b49db1-ac54-410b-9092-534ea82cec0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.823365Z",
     "iopub.status.busy": "2025-07-27T19:17:51.823002Z",
     "iopub.status.idle": "2025-07-27T19:17:51.832366Z",
     "shell.execute_reply": "2025-07-27T19:17:51.831539Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.823333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Missing Value Patterns:\n",
      "Missing Age values:\n",
      "       age   salary department\n",
      "44     NaN  60000.0  Marketing\n",
      "115    NaN  60000.0         IT\n",
      "127    NaN      NaN  Marketing\n",
      "147    NaN  60000.0         HR\n",
      "164    NaN  70000.0         IT\n",
      "...    ...      ...        ...\n",
      "19872  NaN  60000.0         HR\n",
      "19921  NaN      NaN         HR\n",
      "19940  NaN  70000.0        NaN\n",
      "19997  NaN  60000.0         IT\n",
      "19998  NaN  60000.0  Marketing\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing patterns\n",
    "print(\"\\nüìä Missing Value Patterns:\")\n",
    "print(\"Missing Age values:\")\n",
    "print(df[df['age'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b91f6e6-b8a0-4528-8009-dbae08ae21f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.833685Z",
     "iopub.status.busy": "2025-07-27T19:17:51.833216Z",
     "iopub.status.idle": "2025-07-27T19:17:51.844024Z",
     "shell.execute_reply": "2025-07-27T19:17:51.843318Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.833655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Salary values\n",
      "        age  salary department\n",
      "5      35.0     NaN         IT\n",
      "11     61.0     NaN         IT\n",
      "13     46.0     NaN        NaN\n",
      "14     48.0     NaN         IT\n",
      "15     61.0     NaN         HR\n",
      "...     ...     ...        ...\n",
      "19984  71.0     NaN        NaN\n",
      "19988  72.0     NaN  Marketing\n",
      "19992  60.0     NaN        NaN\n",
      "19993  76.0     NaN  Marketing\n",
      "19999  47.0     NaN        NaN\n",
      "\n",
      "[6481 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Salary values\")\n",
    "print(df[df['salary'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "12df9538-38f3-42d2-a62e-08e5ba0af6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.846170Z",
     "iopub.status.busy": "2025-07-27T19:17:51.845570Z",
     "iopub.status.idle": "2025-07-27T19:17:51.854260Z",
     "shell.execute_reply": "2025-07-27T19:17:51.853574Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.846148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Median 48.0\n",
      "Salary Median 60000.0\n"
     ]
    }
   ],
   "source": [
    "# Get the median values for age, and salary\n",
    "age_median = df['age'].median()\n",
    "salary_median = df['salary'].median()\n",
    "print(\"Age Median\", age_median)\n",
    "print(\"Salary Median\", salary_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c2bc0570-6fc5-464c-81d8-a02a3adba273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.855624Z",
     "iopub.status.busy": "2025-07-27T19:17:51.855160Z",
     "iopub.status.idle": "2025-07-27T19:17:51.862060Z",
     "shell.execute_reply": "2025-07-27T19:17:51.861074Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.855594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill missing values of age with age_median\n",
    "df['age'] = df['age'].fillna(age_median)\n",
    "# Fill missing values of salary with salary_median\n",
    "df['salary'] = df['salary'].fillna(salary_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fb165-2329-462f-a31e-95c68398c2bd",
   "metadata": {},
   "source": [
    "#### Age & Salary columns missing values are filled with the respective median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b85aacbe-1f52-4c17-8e8f-6ad235eb3c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.864037Z",
     "iopub.status.busy": "2025-07-27T19:17:51.863697Z",
     "iopub.status.idle": "2025-07-27T19:17:51.878193Z",
     "shell.execute_reply": "2025-07-27T19:17:51.877536Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.864017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "name             0\n",
       "age              0\n",
       "salary           0\n",
       "hire_date     2066\n",
       "profile       2033\n",
       "department    3997\n",
       "bonus         1999\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the Age & Salary data\n",
    "df.head()\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c09aa2-0bc1-473f-8c76-f19774a5d739",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 2: Handle Missing values of Department\n",
    "Handle missing values in categorical columns:\n",
    "- For department: Use 'Unknown' category\n",
    "- This preserves the information that the department was missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "47976d92-55aa-47c2-9ff7-6a4e17c63130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.880176Z",
     "iopub.status.busy": "2025-07-27T19:17:51.879829Z",
     "iopub.status.idle": "2025-07-27T19:17:51.892242Z",
     "shell.execute_reply": "2025-07-27T19:17:51.891563Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.880154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the missing values for Department\n",
      "\n",
      "Missing Department Missing values\n",
      "        age   salary department\n",
      "3      36.0  70000.0        NaN\n",
      "13     46.0  60000.0        NaN\n",
      "49     34.0  50000.0        NaN\n",
      "53     33.0  60000.0        NaN\n",
      "57     28.0  70000.0        NaN\n",
      "...     ...      ...        ...\n",
      "19973  50.0  60000.0        NaN\n",
      "19975  29.0  60000.0        NaN\n",
      "19984  71.0  60000.0        NaN\n",
      "19992  60.0  60000.0        NaN\n",
      "19999  47.0  60000.0        NaN\n",
      "\n",
      "[3997 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print the missing values for Department\\n\")\n",
    "print(\"Missing Department Missing values\")\n",
    "print(df[df['department'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "74e3c4fe-2eff-4254-afc8-72f131d1337a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.894405Z",
     "iopub.status.busy": "2025-07-27T19:17:51.894033Z",
     "iopub.status.idle": "2025-07-27T19:17:51.900794Z",
     "shell.execute_reply": "2025-07-27T19:17:51.900068Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.894384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill the missing values in department with 'Unknown'\n",
    "df['department'] = df['department'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161cef80-1465-4bf7-a5dd-77c98d726590",
   "metadata": {},
   "source": [
    "#### Department column missing values are filled with the respective median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "45cc852e-7cad-4d18-bd6a-b5399e65ebb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.902255Z",
     "iopub.status.busy": "2025-07-27T19:17:51.901944Z",
     "iopub.status.idle": "2025-07-27T19:17:51.918061Z",
     "shell.execute_reply": "2025-07-27T19:17:51.917208Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.902230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column\n",
      "id               0\n",
      "name             0\n",
      "age              0\n",
      "salary           0\n",
      "hire_date     2066\n",
      "profile       2033\n",
      "department       0\n",
      "bonus         1999\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Marketing', 'HR', 'Unknown', 'IT', 'Finance'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the Age & Salary data\n",
    "df.head()\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column\")\n",
    "print(df.isnull().sum())\n",
    "# Check unique values in the department column\n",
    "df['department'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df4a53-6359-4802-979d-df7070a57e9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 3: Parse and Extract Profile Information\n",
    "Devide Profile Column into 3 different columns i.e., Address, Phone, Email   \n",
    "\n",
    "Parse JSON profile data and extract structured information:\n",
    "- Extract address, phone, and email into separate columns\n",
    "- Handle malformed JSON gracefully\n",
    "- Maintain data integrity during extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "40e044cc-fb5c-4b9a-a5f2-bfb99b07add1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.920264Z",
     "iopub.status.busy": "2025-07-27T19:17:51.919729Z",
     "iopub.status.idle": "2025-07-27T19:17:51.975679Z",
     "shell.execute_reply": "2025-07-27T19:17:51.975022Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.920233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top rows from profile column \n",
      "\n",
      "0    {\"address\": \"Street 51, City 12\", \"phone\": \"73...\n",
      "1    {\"address\": \"Street 12, City 6\", \"phone\": \"963...\n",
      "2                                                  NaN\n",
      "3    {\"address\": \"Street 17, City 5\", \"phone\": \"842...\n",
      "4    {\"address\": \"Street 98, City 37\", \"phone\": \"81...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Profile column values current data type\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "\n",
    "# Find the first non-null value in the column\n",
    "profile_first_value = df['profile'].dropna().iloc[0]\n",
    "# Print its type\n",
    "print(\"\\nProfile column values current data type\")\n",
    "print(type(profile_first_value))\n",
    "\n",
    "# If your 'profile' column already contains Python dictionaries, not JSON strings.\n",
    "# You do not need to parse it with json.loads(). The data is ready to be used directly.\n",
    "\n",
    "# Convert profile JSON strings into dictionaries\n",
    "df['profile'] = df['profile'].apply(lambda x: json.loads(x) if pd.notnull(x) else {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "10b5d994-5d55-438e-93fd-ff2042cffffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.977011Z",
     "iopub.status.busy": "2025-07-27T19:17:51.976588Z",
     "iopub.status.idle": "2025-07-27T19:17:51.991814Z",
     "shell.execute_reply": "2025-07-27T19:17:51.991022Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.976980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Address Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0    {'address': 'Street 51, City 12', 'phone': '73...\n",
      "1    {'address': 'Street 12, City 6', 'phone': '963...\n",
      "2                                                   {}\n",
      "3    {'address': 'Street 17, City 5', 'phone': '842...\n",
      "4    {'address': 'Street 98, City 37', 'phone': '81...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created address column \n",
      "\n",
      "0    Street 51, City 12\n",
      "1     Street 12, City 6\n",
      "2                  None\n",
      "3     Street 17, City 5\n",
      "4    Street 98, City 37\n",
      "Name: address, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract Address Field\n",
    "print(\"Extract Address Field....\\n\")\n",
    "# Create new 'address' column by extracting from 'profile' dictionaries\n",
    "df['address'] = df['profile'].apply(lambda x: x.get('address', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created address column \\n\")\n",
    "print(df['address'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "af5fbe45-27ac-4eef-992f-79d4895060a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:51.993349Z",
     "iopub.status.busy": "2025-07-27T19:17:51.993032Z",
     "iopub.status.idle": "2025-07-27T19:17:52.006475Z",
     "shell.execute_reply": "2025-07-27T19:17:52.005551Z",
     "shell.execute_reply.started": "2025-07-27T19:17:51.993318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Phone Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0    {'address': 'Street 51, City 12', 'phone': '73...\n",
      "1    {'address': 'Street 12, City 6', 'phone': '963...\n",
      "2                                                   {}\n",
      "3    {'address': 'Street 17, City 5', 'phone': '842...\n",
      "4    {'address': 'Street 98, City 37', 'phone': '81...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created phone column \n",
      "\n",
      "0    7323475298\n",
      "1    9633478479\n",
      "2          None\n",
      "3    8423075763\n",
      "4    8158889415\n",
      "Name: phone, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract Phone Field\n",
    "print(\"Extract Phone Field....\\n\")\n",
    "# Create new 'phone' column by extracting from 'profile' dictionaries\n",
    "df['phone'] = df['profile'].apply(lambda x: x.get('phone', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created phone column \\n\")\n",
    "print(df['phone'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aebdb099-5095-4149-b957-119ae9fccaa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.007902Z",
     "iopub.status.busy": "2025-07-27T19:17:52.007486Z",
     "iopub.status.idle": "2025-07-27T19:17:52.022871Z",
     "shell.execute_reply": "2025-07-27T19:17:52.022195Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.007873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Email Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0    {'address': 'Street 51, City 12', 'phone': '73...\n",
      "1    {'address': 'Street 12, City 6', 'phone': '963...\n",
      "2                                                   {}\n",
      "3    {'address': 'Street 17, City 5', 'phone': '842...\n",
      "4    {'address': 'Street 98, City 37', 'phone': '81...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created email column \n",
      "\n",
      "0    email_140@example.com\n",
      "1     email_38@example.com\n",
      "2                     None\n",
      "3    email_194@example.com\n",
      "4    email_592@example.com\n",
      "Name: email, dtype: object\n",
      "\n",
      "‚úÖ Profile fields extracted:\n"
     ]
    }
   ],
   "source": [
    "# Extract Email Field\n",
    "print(\"Extract Email Field....\\n\")\n",
    "# Create new 'email' column by extracting from 'profile' dictionaries\n",
    "df['email'] = df['profile'].apply(lambda x: x.get('email', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created email column \\n\")\n",
    "print(df['email'].head())\n",
    "\n",
    "print(f\"\\n‚úÖ Profile fields extracted:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ee1aeb4-dac9-40f4-8455-1a24e1e8ff1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.025053Z",
     "iopub.status.busy": "2025-07-27T19:17:52.024336Z",
     "iopub.status.idle": "2025-07-27T19:17:52.037176Z",
     "shell.execute_reply": "2025-07-27T19:17:52.036438Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.025023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns before dropping profile:\n",
      "['id', 'name', 'age', 'salary', 'hire_date', 'profile', 'department', 'bonus', 'address', 'phone', 'email']\n",
      "\n",
      "Columns in new DataFrame after dropping profile:\n",
      "['id', 'name', 'age', 'salary', 'hire_date', 'department', 'bonus', 'address', 'phone', 'email']\n"
     ]
    }
   ],
   "source": [
    "# Now drop the profile column\n",
    "print(\"\\nColumns before dropping profile:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Without inplace=True (df remains unchanged)\n",
    "cleaned_df = df.drop(columns=['profile'])\n",
    "\n",
    "# With inplace=True (df is modified directly)\n",
    "#df.drop(columns=['profile'], inplace=True)\n",
    "\n",
    "print(\"\\nColumns in new DataFrame after dropping profile:\")\n",
    "# print(df.columns.tolist())\n",
    "print(cleaned_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb385e-e37f-41ec-9c6b-5634419dc89a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 4: Save cleaned data into new CSV and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d9f9bfbc-83de-433d-8461-d43f5d088731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.038954Z",
     "iopub.status.busy": "2025-07-27T19:17:52.038621Z",
     "iopub.status.idle": "2025-07-27T19:17:52.199962Z",
     "shell.execute_reply": "2025-07-27T19:17:52.199173Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.038922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saving cleaned data to: 'data/cleaned_data.csv' ...\n",
      "‚úÖ Cleaned data saved to: 'data/cleaned_data.csv'\n",
      "\n",
      "Uploading dataset to s3 bucket: sagemaker-us-east-1-891377300841\n",
      "Dataset 'mock_data.csv' uploaded to: s3://sagemaker-us-east-1-891377300841/output/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíæ Saving cleaned data to: 'data/cleaned_data.csv' ...\")\n",
    "cleaned_df.to_csv(\"data/cleaned_data.csv\", index=False)\n",
    "print(\"‚úÖ Cleaned data saved to: 'data/cleaned_data.csv'\")\n",
    "\n",
    "print(f\"\\nUploading dataset to s3 bucket: {bucket}\")\n",
    "s3.meta.client.upload_file('data/cleaned_data.csv', bucket, 'output/cleaned_data.csv')\n",
    "print(f\"Dataset 'mock_data.csv' uploaded to: s3://{bucket}/output/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb68ace-9dce-4caf-9217-a25106886373",
   "metadata": {},
   "source": [
    "## 4. Data Transformation & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41937110-6255-4cc3-a4ce-cfb0d7fb91d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 1: Load the cleaned dataset into new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1f36252c-0d27-44c4-9a51-25876ee35fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.201336Z",
     "iopub.status.busy": "2025-07-27T19:17:52.200790Z",
     "iopub.status.idle": "2025-07-27T19:17:52.288378Z",
     "shell.execute_reply": "2025-07-27T19:17:52.287726Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.201315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Name_103</td>\n",
       "      <td>77.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>8767.0</td>\n",
       "      <td>Street 51, City 12</td>\n",
       "      <td>7.323475e+09</td>\n",
       "      <td>email_140@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Name_436</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>7553.0</td>\n",
       "      <td>Street 12, City 6</td>\n",
       "      <td>9.633478e+09</td>\n",
       "      <td>email_38@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Name_861</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>HR</td>\n",
       "      <td>6796.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Name_271</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8712.0</td>\n",
       "      <td>Street 17, City 5</td>\n",
       "      <td>8.423076e+09</td>\n",
       "      <td>email_194@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Name_107</td>\n",
       "      <td>78.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2017-06-17</td>\n",
       "      <td>IT</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>Street 98, City 37</td>\n",
       "      <td>8.158889e+09</td>\n",
       "      <td>email_592@example.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name   age   salary   hire_date department   bonus  \\\n",
       "0   1  Name_103  77.0  60000.0  2023-05-11  Marketing  8767.0   \n",
       "1   2  Name_436  62.0  50000.0  2021-04-22  Marketing  7553.0   \n",
       "2   3  Name_861  61.0  60000.0  2022-04-18         HR  6796.0   \n",
       "3   4  Name_271  36.0  70000.0         NaN    Unknown  8712.0   \n",
       "4   5  Name_107  78.0  60000.0  2017-06-17         IT  3340.0   \n",
       "\n",
       "              address         phone                  email  \n",
       "0  Street 51, City 12  7.323475e+09  email_140@example.com  \n",
       "1   Street 12, City 6  9.633478e+09   email_38@example.com  \n",
       "2                 NaN           NaN                    NaN  \n",
       "3   Street 17, City 5  8.423076e+09  email_194@example.com  \n",
       "4  Street 98, City 37  8.158889e+09  email_592@example.com  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df = pd.read_csv(f's3://{bucket}/output/cleaned_data.csv')\n",
    "transform_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4589364-d7f7-4d82-a6a3-873ded9a45e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 2 : Feature Engineering - Address Length\n",
    "Create address length feature for potential geographic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5054fd88-4a6f-4a78-a1e1-777b05db61e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.289880Z",
     "iopub.status.busy": "2025-07-27T19:17:52.289352Z",
     "iopub.status.idle": "2025-07-27T19:17:52.307672Z",
     "shell.execute_reply": "2025-07-27T19:17:52.306956Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.289857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Address Length Feature...\n",
      "Address followed by Address Length columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Street 51, City 12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Street 12, City 6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street 17, City 5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Street 98, City 37</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              address  address_length\n",
       "0  Street 51, City 12              18\n",
       "1   Street 12, City 6              17\n",
       "2                 NaN               3\n",
       "3   Street 17, City 5              17\n",
       "4  Street 98, City 37              18"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'address_length' \n",
    "print(\"\\nüîß Creating Address Length Feature...\")\n",
    "transform_df['address_length'] = transform_df['address'].apply(lambda x: len(str(x)))\n",
    "print(\"Address followed by Address Length columns\")\n",
    "transform_df[['address', 'address_length']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a3a74-21ab-42bb-a0c0-3654bd30762e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 3: Feature Engineering - Salary Categorization\n",
    "Create salary categories for easier analysis and modeling.  \n",
    "This converts continuous salary into ordinal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8273466c-9379-4d78-b658-0837258d5cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.308871Z",
     "iopub.status.busy": "2025-07-27T19:17:52.308532Z",
     "iopub.status.idle": "2025-07-27T19:17:52.321307Z",
     "shell.execute_reply": "2025-07-27T19:17:52.320737Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.308850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Salary Categories...\n",
      "Sample data after adding the 'salary_category' column: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salary salary_category\n",
       "0  60000.0          medium\n",
       "1  50000.0             low\n",
       "2  60000.0          medium\n",
       "3  70000.0          medium\n",
       "4  60000.0          medium"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nüîß Creating Salary Categories...\")\n",
    "# Define the bins and labels\n",
    "bins = [0, 50000, 70000, 100000]\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# Create a new column 'salary_category'\n",
    "transform_df['salary_category'] = pd.cut(df['salary'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Print sample data after adding the 'salary_category' column\n",
    "print(\"Sample data after adding the 'salary_category' column: \\n\")\n",
    "transform_df[['salary', 'salary_category']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5499d-ae91-4868-a45a-873757984b1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 4: Feature Engineering - Age Groups  \n",
    "Create age groups for demographic analysis.  \n",
    "This helps in understanding age-based patterns in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a60a508-591e-4bc8-a8dc-21b8ef5f15d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.325283Z",
     "iopub.status.busy": "2025-07-27T19:17:52.324788Z",
     "iopub.status.idle": "2025-07-27T19:17:52.341096Z",
     "shell.execute_reply": "2025-07-27T19:17:52.340430Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.325256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Age Groups...\n",
      "Age group distribution:\n",
      "age_group\n",
      "Experienced     7318\n",
      "Senior          4068\n",
      "Early Career    3142\n",
      "Mid Career      3022\n",
      "Young           2450\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data after adding the 'age_group' column: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Mid Career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.0</td>\n",
       "      <td>Experienced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    age_group\n",
       "0  77.0  Experienced\n",
       "1  62.0  Experienced\n",
       "2  61.0  Experienced\n",
       "3  36.0   Mid Career\n",
       "4  78.0  Experienced"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nüîß Creating Age Groups...\")\n",
    "# Define age bins and labels\n",
    "age_bins = [0, 25, 35, 45, 55, float('inf')]\n",
    "age_labels = ['Young', 'Early Career', 'Mid Career', 'Senior', 'Experienced']\n",
    "\n",
    "# Create a new column 'salary_category'\n",
    "transform_df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "# Age group distribution\n",
    "print(f\"Age group distribution:\")\n",
    "print(transform_df['age_group'].value_counts())\n",
    "\n",
    "# Print sample data after adding the 'salary_category' column\n",
    "print(\"\\nSample data after adding the 'age_group' column: \\n\")\n",
    "transform_df[['age', 'age_group']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b29fe3-0142-4bcf-9b99-d461e04b2d38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 5: Feature Engineering - One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "587df725-b036-4d3d-8334-74348b572845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.342586Z",
     "iopub.status.busy": "2025-07-27T19:17:52.342274Z",
     "iopub.status.idle": "2025-07-27T19:17:52.369391Z",
     "shell.execute_reply": "2025-07-27T19:17:52.368657Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.342561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows with boolean values\n",
      "   id      name   age   salary   hire_date   bonus             address  \\\n",
      "0   1  Name_103  77.0  60000.0  2023-05-11  8767.0  Street 51, City 12   \n",
      "1   2  Name_436  62.0  50000.0  2021-04-22  7553.0   Street 12, City 6   \n",
      "2   3  Name_861  61.0  60000.0  2022-04-18  6796.0                 NaN   \n",
      "3   4  Name_271  36.0  70000.0         NaN  8712.0   Street 17, City 5   \n",
      "4   5  Name_107  78.0  60000.0  2017-06-17  3340.0  Street 98, City 37   \n",
      "\n",
      "          phone                  email  address_length salary_category  \\\n",
      "0  7.323475e+09  email_140@example.com              18          medium   \n",
      "1  9.633478e+09   email_38@example.com              17             low   \n",
      "2           NaN                    NaN               3          medium   \n",
      "3  8.423076e+09  email_194@example.com              17          medium   \n",
      "4  8.158889e+09  email_592@example.com              18          medium   \n",
      "\n",
      "     age_group  dept_Finance  dept_HR  dept_IT  dept_Marketing  dept_Unknown  \n",
      "0  Experienced         False    False    False            True         False  \n",
      "1  Experienced         False    False    False            True         False  \n",
      "2  Experienced         False     True    False           False         False  \n",
      "3   Mid Career         False    False    False           False          True  \n",
      "4  Experienced         False    False     True           False         False  \n",
      "\n",
      "Top 5 rows with numberic values\n",
      "\n",
      "   id      name   age   salary   hire_date   bonus             address  \\\n",
      "0   1  Name_103  77.0  60000.0  2023-05-11  8767.0  Street 51, City 12   \n",
      "1   2  Name_436  62.0  50000.0  2021-04-22  7553.0   Street 12, City 6   \n",
      "2   3  Name_861  61.0  60000.0  2022-04-18  6796.0                 NaN   \n",
      "3   4  Name_271  36.0  70000.0         NaN  8712.0   Street 17, City 5   \n",
      "4   5  Name_107  78.0  60000.0  2017-06-17  3340.0  Street 98, City 37   \n",
      "\n",
      "          phone                  email  address_length salary_category  \\\n",
      "0  7.323475e+09  email_140@example.com              18          medium   \n",
      "1  9.633478e+09   email_38@example.com              17             low   \n",
      "2           NaN                    NaN               3          medium   \n",
      "3  8.423076e+09  email_194@example.com              17          medium   \n",
      "4  8.158889e+09  email_592@example.com              18          medium   \n",
      "\n",
      "     age_group  dept_Finance  dept_HR  dept_IT  dept_Marketing  dept_Unknown  \n",
      "0  Experienced             0        0        0               1             0  \n",
      "1  Experienced             0        0        0               1             0  \n",
      "2  Experienced             0        1        0               0             0  \n",
      "3   Mid Career             0        0        0               0             1  \n",
      "4  Experienced             0        0        1               0             0  \n"
     ]
    }
   ],
   "source": [
    "transform_df = pd.get_dummies(transform_df, columns=['department'], prefix='dept')\n",
    "print(\"Top 5 rows with boolean values\")\n",
    "print(transform_df.head())\n",
    "\n",
    "bool_cols = transform_df.select_dtypes(include='bool').columns\n",
    "transform_df[bool_cols] = transform_df[bool_cols].astype(int)\n",
    "\n",
    "print(\"\\nTop 5 rows with numberic values\\n\")\n",
    "print(transform_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4dd85-4808-4092-84a7-9884b356b2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T17:33:57.674942Z",
     "iopub.status.busy": "2025-07-27T17:33:57.674660Z",
     "iopub.status.idle": "2025-07-27T17:33:57.686040Z",
     "shell.execute_reply": "2025-07-27T17:33:57.685195Z",
     "shell.execute_reply.started": "2025-07-27T17:33:57.674921Z"
    },
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 6: Remove missing values in bonus (is the target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b3e6dcb0-6ddd-4aa1-b71c-23f7643ca281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.372632Z",
     "iopub.status.busy": "2025-07-27T19:17:52.370370Z",
     "iopub.status.idle": "2025-07-27T19:17:52.393419Z",
     "shell.execute_reply": "2025-07-27T19:17:52.392772Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.372608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Missing Values Analysis before Removing Missing:\n",
      "\n",
      "id                    0\n",
      "name                  0\n",
      "age                   0\n",
      "salary                0\n",
      "hire_date          2066\n",
      "bonus              1999\n",
      "address            2033\n",
      "phone              2033\n",
      "email              2033\n",
      "address_length        0\n",
      "salary_category       0\n",
      "age_group             0\n",
      "dept_Finance          0\n",
      "dept_HR               0\n",
      "dept_IT               0\n",
      "dept_Marketing        0\n",
      "dept_Unknown          0\n",
      "dtype: int64\n",
      "\n",
      "‚ùì Missing Values Analysis after Removing Missing:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "name                  0\n",
       "age                   0\n",
       "salary                0\n",
       "hire_date          1863\n",
       "bonus                 0\n",
       "address            1808\n",
       "phone              1808\n",
       "email              1808\n",
       "address_length        0\n",
       "salary_category       0\n",
       "age_group             0\n",
       "dept_Finance          0\n",
       "dept_HR               0\n",
       "dept_IT               0\n",
       "dept_Marketing        0\n",
       "dept_Unknown          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n‚ùì Missing Values Analysis before Removing Missing:\\n\")\n",
    "print(transform_df.isnull().sum())\n",
    "\n",
    "# Remove missing rows for bonus\n",
    "transform_df = transform_df[transform_df['bonus'].notna()]\n",
    "print(\"\\n‚ùì Missing Values Analysis after Removing Missing:\\n\")\n",
    "transform_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b2889-5c28-4965-a604-33d779b8311c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:12:34.504037Z",
     "iopub.status.busy": "2025-07-27T18:12:34.503634Z",
     "iopub.status.idle": "2025-07-27T18:12:34.507819Z",
     "shell.execute_reply": "2025-07-27T18:12:34.506903Z",
     "shell.execute_reply.started": "2025-07-27T18:12:34.504011Z"
    },
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 7: Feature Engineering - One-Hot Encoding on age_group & salary_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6dd51715-3c3e-4ea4-9960-ce5f7364c44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.395831Z",
     "iopub.status.busy": "2025-07-27T19:17:52.395289Z",
     "iopub.status.idle": "2025-07-27T19:17:52.430289Z",
     "shell.execute_reply": "2025-07-27T19:17:52.429269Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.395809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows with boolean values\n",
      "   id      name   age   salary   hire_date   bonus             address  \\\n",
      "0   1  Name_103  77.0  60000.0  2023-05-11  8767.0  Street 51, City 12   \n",
      "1   2  Name_436  62.0  50000.0  2021-04-22  7553.0   Street 12, City 6   \n",
      "2   3  Name_861  61.0  60000.0  2022-04-18  6796.0                 NaN   \n",
      "3   4  Name_271  36.0  70000.0         NaN  8712.0   Street 17, City 5   \n",
      "4   5  Name_107  78.0  60000.0  2017-06-17  3340.0  Street 98, City 37   \n",
      "\n",
      "          phone                  email  address_length  ...  dept_Marketing  \\\n",
      "0  7.323475e+09  email_140@example.com              18  ...               1   \n",
      "1  9.633478e+09   email_38@example.com              17  ...               1   \n",
      "2           NaN                    NaN               3  ...               0   \n",
      "3  8.423076e+09  email_194@example.com              17  ...               0   \n",
      "4  8.158889e+09  email_592@example.com              18  ...               0   \n",
      "\n",
      "   dept_Unknown  age_Young  age_Early Career  age_Mid Career  age_Senior  \\\n",
      "0             0      False             False           False       False   \n",
      "1             0      False             False           False       False   \n",
      "2             0      False             False           False       False   \n",
      "3             1      False             False            True       False   \n",
      "4             0      False             False           False       False   \n",
      "\n",
      "   age_Experienced  salary_low  salary_medium  salary_high  \n",
      "0             True       False           True        False  \n",
      "1             True        True          False        False  \n",
      "2             True       False           True        False  \n",
      "3            False       False           True        False  \n",
      "4             True       False           True        False  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Top 5 rows with numberic values\n",
      "\n",
      "   id      name   age   salary   hire_date   bonus             address  \\\n",
      "0   1  Name_103  77.0  60000.0  2023-05-11  8767.0  Street 51, City 12   \n",
      "1   2  Name_436  62.0  50000.0  2021-04-22  7553.0   Street 12, City 6   \n",
      "2   3  Name_861  61.0  60000.0  2022-04-18  6796.0                 NaN   \n",
      "3   4  Name_271  36.0  70000.0         NaN  8712.0   Street 17, City 5   \n",
      "4   5  Name_107  78.0  60000.0  2017-06-17  3340.0  Street 98, City 37   \n",
      "\n",
      "          phone                  email  address_length  ...  dept_Marketing  \\\n",
      "0  7.323475e+09  email_140@example.com              18  ...               1   \n",
      "1  9.633478e+09   email_38@example.com              17  ...               1   \n",
      "2           NaN                    NaN               3  ...               0   \n",
      "3  8.423076e+09  email_194@example.com              17  ...               0   \n",
      "4  8.158889e+09  email_592@example.com              18  ...               0   \n",
      "\n",
      "   dept_Unknown  age_Young  age_Early Career  age_Mid Career  age_Senior  \\\n",
      "0             0          0                 0               0           0   \n",
      "1             0          0                 0               0           0   \n",
      "2             0          0                 0               0           0   \n",
      "3             1          0                 0               1           0   \n",
      "4             0          0                 0               0           0   \n",
      "\n",
      "   age_Experienced  salary_low  salary_medium  salary_high  \n",
      "0                1           0              1            0  \n",
      "1                1           1              0            0  \n",
      "2                1           0              1            0  \n",
      "3                0           0              1            0  \n",
      "4                1           0              1            0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "transform_df = pd.get_dummies(transform_df, columns=['age_group', 'salary_category'], prefix=['age', 'salary'])\n",
    "print(\"Top 5 rows with boolean values\")\n",
    "print(transform_df.head())\n",
    "\n",
    "bool_cols = transform_df.select_dtypes(include='bool').columns\n",
    "transform_df[bool_cols] = transform_df[bool_cols].astype(int)\n",
    "\n",
    "print(\"\\nTop 5 rows with numberic values\\n\")\n",
    "print(transform_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc32b5-5ddc-4dd4-b57f-7593195d4d21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 8: Feature Engineering | Calculate Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "68f7db69-be7e-4cd4-af46-65253bc71d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.431696Z",
     "iopub.status.busy": "2025-07-27T19:17:52.431462Z",
     "iopub.status.idle": "2025-07-27T19:17:52.448717Z",
     "shell.execute_reply": "2025-07-27T19:17:52.447870Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.431676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert hire_date to datetime\n",
      "0   2023-05-11\n",
      "1   2021-04-22\n",
      "2   2022-04-18\n",
      "3          NaT\n",
      "4   2017-06-17\n",
      "Name: hire_date, dtype: datetime64[ns]\n",
      "Calculate Tenure in Days....\n",
      "Calculated Tenure Days\n",
      "0         808.0\n",
      "1        1557.0\n",
      "2        1196.0\n",
      "3           NaN\n",
      "4        2962.0\n",
      "          ...  \n",
      "19994     549.0\n",
      "19996    3570.0\n",
      "19997    3498.0\n",
      "19998     253.0\n",
      "19999    1097.0\n",
      "Name: tenure_days, Length: 18001, dtype: float64\n",
      "Handle Missing values of tenure_days\n",
      "Tenure Days after handled missing days\n",
      "0         808.0\n",
      "1        1557.0\n",
      "2        1196.0\n",
      "3        1834.0\n",
      "4        2962.0\n",
      "          ...  \n",
      "19994     549.0\n",
      "19996    3570.0\n",
      "19997    3498.0\n",
      "19998     253.0\n",
      "19999    1097.0\n",
      "Name: tenure_days, Length: 18001, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Convert hire_date to datetime\")\n",
    "transform_df['hire_date'] = pd.to_datetime(transform_df['hire_date'], errors='coerce')\n",
    "print(transform_df['hire_date'].head())\n",
    "# print(transform_df.dtypes)\n",
    "\n",
    "# non_date_rows = transform_df[transform_df['hire_date'].apply(lambda x: isinstance(x, str))]\n",
    "# print(\"non date rows:\")\n",
    "# print(non_date_rows)\n",
    "\n",
    "print(\"Calculate Tenure in Days....\")\n",
    "transform_df['tenure_days'] = (pd.Timestamp('now') - transform_df['hire_date']).dt.days\n",
    "\n",
    "print(\"Calculated Tenure Days\")\n",
    "print(transform_df['tenure_days'])\n",
    "\n",
    "print(\"Handle Missing values of tenure_days\")\n",
    "transform_df['tenure_days'] = transform_df['tenure_days'].fillna(transform_df['tenure_days'].median())\n",
    "\n",
    "print(\"Tenure Days after handled missing days\")\n",
    "print(transform_df['tenure_days'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51943479-aee6-4538-9ad4-1e6571d6a661",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 9: Feature Engineering | Removing Irrelevant or non-predictive columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2c1a7779-1960-44d6-869a-3e52055a6fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.450382Z",
     "iopub.status.busy": "2025-07-27T19:17:52.449934Z",
     "iopub.status.idle": "2025-07-27T19:17:52.462725Z",
     "shell.execute_reply": "2025-07-27T19:17:52.461747Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.450353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping ID, Address, Phone, Name, Hire Date, and Email.....\n",
      "After dropping ID, Address, Phone, Name, Hire Date, and Email, dataset look like\n",
      "    age   salary   bonus  address_length  dept_Finance  dept_HR  dept_IT  \\\n",
      "0  77.0  60000.0  8767.0              18             0        0        0   \n",
      "1  62.0  50000.0  7553.0              17             0        0        0   \n",
      "2  61.0  60000.0  6796.0               3             0        1        0   \n",
      "3  36.0  70000.0  8712.0              17             0        0        0   \n",
      "4  78.0  60000.0  3340.0              18             0        0        1   \n",
      "\n",
      "   dept_Marketing  dept_Unknown  age_Young  age_Early Career  age_Mid Career  \\\n",
      "0               1             0          0                 0               0   \n",
      "1               1             0          0                 0               0   \n",
      "2               0             0          0                 0               0   \n",
      "3               0             1          0                 0               1   \n",
      "4               0             0          0                 0               0   \n",
      "\n",
      "   age_Senior  age_Experienced  salary_low  salary_medium  salary_high  \\\n",
      "0           0                1           0              1            0   \n",
      "1           0                1           1              0            0   \n",
      "2           0                1           0              1            0   \n",
      "3           0                0           0              1            0   \n",
      "4           0                1           0              1            0   \n",
      "\n",
      "   tenure_days  \n",
      "0        808.0  \n",
      "1       1557.0  \n",
      "2       1196.0  \n",
      "3       1834.0  \n",
      "4       2962.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping ID, Address, Phone, Name, Hire Date, and Email.....\")\n",
    "transform_df.drop(columns=['id', 'address', 'phone', 'email', 'name', 'hire_date'], inplace=True)\n",
    "print(\"After dropping ID, Address, Phone, Name, Hire Date, and Email, dataset look like\")\n",
    "print(transform_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc636561-1dd7-464e-b908-de230785c662",
   "metadata": {},
   "source": [
    "### Step 7: Save the transformed DataFrame to a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "effa94fc-c979-4bda-a3bd-fb00e38457ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T19:17:52.464093Z",
     "iopub.status.busy": "2025-07-27T19:17:52.463657Z",
     "iopub.status.idle": "2025-07-27T19:17:52.636013Z",
     "shell.execute_reply": "2025-07-27T19:17:52.635169Z",
     "shell.execute_reply.started": "2025-07-27T19:17:52.464061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Transformed data csv to: 'data/transformed_data.csv' ...\n",
      "\n",
      "Transformed data csv saved to: 'data/transformed_data.csv'\n",
      "Transformed data 'transformed_data.csv' uploaded to: s3://sagemaker-us-east-1-891377300841/output/transformed_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving Transformed data csv to: 'data/transformed_data.csv' ...\")\n",
    "transform_df.to_csv(\"data/transformed_data.csv\", index=False)\n",
    "print(\"\\nTransformed data csv saved to: 'data/transformed_data.csv'\")\n",
    "\n",
    "s3.meta.client.upload_file('data/transformed_data.csv', bucket, 'output/transformed_data.csv')\n",
    "print(f\"Transformed data 'transformed_data.csv' uploaded to: s3://{bucket}/output/transformed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
